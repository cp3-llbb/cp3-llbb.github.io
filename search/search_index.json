{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"What is this wiki about?","text":"<p>This wiki presents the code used by the CP3-llbb group, to perform analyses of p-p collisions collected by the CMS experiment</p>"},{"location":"#what-are-the-prerequisites","title":"What are the prerequisites?","text":"<p>If you intend to use the code in its vanilla version, you need:</p> <ul> <li>an access to ingrid, see the CP3-IT FAQ to get some more info</li> <li>some knowledge of CMSSW, the CMS software</li> </ul> <p>If you intend to develop and follow what other do, it is a (very recommended) good idea to:</p> <ul> <li>follow the llbb group meetings</li> <li>register to the cp3-llbb CERN egroup</li> <li>have some knowledge about using git:<ul> <li>this online book is a nice one</li> <li>this five-minutes introduction presents the workflow we use for developing code</li> </ul> </li> <li>ask questions!</li> <li>do not be shy of posting issues if you notice what you think is a bug</li> <li>do not hesitate to make suggestions about improving any documentation if things are not clear </li> </ul>"},{"location":"#there-is-plenty-of-repositories-here-what-do-i-do","title":"There is plenty of repositories here, what do I do?","text":"<p>Specific instructions on how to install and use them should be in the README of each repository (if not, do complain). The flow is the following:</p> <ul> <li> <p>CMSSW code (The technical documentation is not yet ready (September 2015)):</p> <ul> <li>the Framework is the core of the code, it transforms MINIAOD objects into non-flat ROOT trees containing the reconstruced leptons, MET, (b)jet, and more. It applies the high-level corrections needed by everyone (leptons SF, JES, JEC, etc.) and also constructs some more high-level objects (dileptons). It can be run stand-alone, but is intended to be used with an analysis (see below). The code is in the Framework repository, and there is also Doxygen reference documentation</li> <li>the analyses (HHAnalysis, TTAnalysis, ZAAnalysis) are CMSSW plugins. The intent of these is to run the framework and gather more info in the trees specific to each analysis (MC truth, reconstruction of the top, the Higgs boson, the Z boson). Except if you want to produce very basic control plots, this is probably what you want to run.</li> </ul> </li> <li> <p>using the grid:</p> <ul> <li>now that we have some CMSSW code compiling and running, you probably want to run it on the grid, with CRAB3, in order to create the trees for many MC and data samples, to perform some analysis</li> <li>GridIn is our CMSSW package to easily do so: it prepares the crab config files so that you just have to launch them</li> <li>if your grid jobs are successful, you want to write down somewhere what is it you've down. To do so we use SAMADhi, our local database (there is also a web interface), to bookkeep what code has been run to produce the trees and where they are stored. The format and links of the database are the displayed below. </li> </ul> </li> <li> <p>produce some plots:</p> <ul> <li>now that you have trees you can make plots. You can use your own code to do so, but given some trees are quite big, we have some utilities to help</li> <li>CommonTools contain helpers, in particular histFactory is here to mass-produce histogram files</li> <li>now that you have histogram files for all your samples, plotIt is a nice utility to stack them and display them in the latest recommended CMS style</li> </ul> </li> </ul>"},{"location":"bamboo/","title":"Bamboo: A high-level HEP analysis library for ROOT::RDataFrame","text":"<p>You can find out more about bamboo in the UserGuide: https://bamboo-hep.readthedocs.io/en/latest/.  Also feel free to report any issue you encounter in ~bamboo channel on the CERN mattermost, or on Gitlab.</p>"},{"location":"framework/","title":"Framework","text":"<p>Common framework for all cp3-llbb analyses</p> <p>Note</p> <ul> <li>The instructions are for the UCLouvain ingrid SLC6 cluster (to access SAMADhi)</li> <li>You need the proper username and password to access SAMADhi :) If you don't know what this is about, ask around</li> <li>The current state of the art mini-AOD documentation can be found here</li> <li>You will probably want to install as well GridIn to run jobs on the grid, and one of the existing analyses (TTAnalysis, HHAnalysis, ZAAnalysis)</li> </ul>"},{"location":"framework/#cmssw-release","title":"CMSSW release","text":"<p>CMSSW_8_0_30</p>"},{"location":"framework/#first-time-setup-instructions","title":"First time setup instructions","text":"<pre><code>## the following two lines can be replaced by a call to the cms_env alias (see below)\nsource /nfs/soft/grid/ui_sl6/setup/grid-env.sh\nsource /cvmfs/cms.cern.ch/cmsset_default.sh\n\nwget https://raw.githubusercontent.com/cp3-llbb/Framework/CMSSW_8_0_6p/setup_project_with_framework.sh\nsource setup_project_with_framework.sh --branch CMSSW_8_0_6p\n</code></pre> <p>The script above will set up a CMSSW release area, apply the recipes in <code>bootstrap_jenkins.sh</code> and <code>jenkins_postbuild.sh</code>, perform an initial build, and add your and your colleagues' forks on GitHub as remotes for your <code>Framework</code> clone (all those that have been pushed to in the last year; you can update the list by running <code>updateremotes</code>). Through the options <code>--branch NAME</code> and <code>--pr ID</code>, a project area for a different version can also be created.</p> <p>If you are using ingrid, here's a useful alias to put in your <code>bashrc</code> file:</p> <pre><code>alias cms_env=\"module purge; module load grid/grid_environment_sl6; module load crab/crab3; module load cms/cmssw; module load slurm/slurm_utils;\"\n</code></pre> <p>Then, just do <code>cms_env</code> to load all the CMSSW environment.</p>"},{"location":"framework/#test-run-command-line","title":"Test run (command line)","text":"<pre><code>cd ${CMSSW_BASE}/src/cp3_llbb/Framework/test\ncmsRun TestConfigurationMC.py\n</code></pre>"},{"location":"framework/#when-willing-to-commit-things","title":"When willing to commit things","text":"<ul> <li>Remember to branch before committing anything: <code>git checkout -b my-new-branch</code></li> <li>Any branches to merge into CMSSW, packages to add, version and <code>SCRAM_ARCH</code> changes should be added to <code>bootstrap_jenkins.sh</code>, <code>jenkins_postbuild.sh</code>, <code>CMSSW.release</code> and <code>CMSSW.arch</code>, respectively, such that they are also picked up by Jenkins, more details here.</li> <li>The <code>updateremotes</code> script (run from <code>setup_project_with_framework.sh</code>) took care of adding <code>origin</code> as your own repo, so to push just do the usual <code>git push origin my-new-branch</code></li> <li>If you change anything to the output trees (new or modified branches, new recipes etc.), the automatic tests (see below) will fail, because they compare the outputs to reference files.   You can resolve this by regenerating the reference files with the <code>test/generate_reference_trees.sh</code> script, after committing your other changes.   It will also print a summary of all differences in the output files. If these are as expected, you can make a new commit with the updated reference files.</li> </ul>"},{"location":"framework/#finding-your-way-around-the-different-modules","title":"Finding your way around the different modules","text":"<p>The Framework configures a CMSSW sequence and runs an <code>edm::EDProducer</code> module, <code>ExTreeMaker</code>, to select events and create a TTree for analysis. The structure is modular, so most of the actual code to select events and fill branches is in the producers, analyzers, filters and categories; <code>ExTreeMaker</code> only knows the interface Producer the different components implement (technically: it only has a pointer to the interface class, and the instances are created by a factory - so you can also add modules in another package).</p> <p>Producers (<code>Framework::producer</code>) are run first, and fill branches for event information that is present in the input file (so not analysis-specific): leptons, jets, event information, weight etc., while analyzers (<code>Framework::analyzer</code> are run later, and typically define analysis-specific and derived objects (selected and cross-cleaned objects, N-object combined candidates). The decision if an the output tree should be written for an event is taken based on the categories (instances of <code>Category</code> implementations, see below). In practice a typical analysis will set up (and perhaps slightly customize) the default set of producers, define one (or more) analyzers, and configure (or extend) categories.</p> <p>Producers and analyzers can readily be understood from an example, but categories involve more interacting components, so the overall picture may be a bit more confusing. The <code>ExTreeMaker::produce</code> method, which is called for every event, first checks if the event passes all filters (another, less frequently used, module type - the interface only specifies a method that returns true or false for every event, without access to the producers), and then executes the following steps:</p> <ul> <li>run all producers</li> <li>check if the event is in any of the categories, based on the producers'   outputs only (<code>Category::event_in_category_pre_analyzers</code>), and skip to the next event if not</li> <li>run all analyzers</li> <li>check if the event is in any of the categories that selected it before,   based on the analyzers' (and produces') outputs (<code>Category::event_in_category_post_analyzers</code>),   and skip to the next event if not</li> <li>save the entry in the tree</li> </ul> <p>Two more things are useful to know about categories: they are register by an analyzer (any analyzer, so one could have two analyzers that each define some categories - the event will be in the output tree as soon as any category from either set accepts the event), and they can also define a set of selections (cuts). These need to be registered (in <code>Category::register_cuts(cutManager)</code>, with <code>CutManager::new_cut(name, description)</code>), and set to <code>true</code>, if applicable, for every event (with <code>CutManager::pass_cut(cutName)</code> - this can be done either before or after running the analyzers (from <code>Category::evaluate_cuts_pre_analyzers</code> or <code>Category::evaluate_cuts_post_analyzers</code>, respectively).</p> <p>The category responses are filled in branches with name <code>&lt;prefix&gt;&lt;categoryname&gt;_category</code>, and the cut responses in branches with name <code>&lt;prefix&gt;&lt;categoryname&gt;_&lt;cutname&gt;_cut</code>, where the prefix is taken from the analyzer that registered the category.</p>"},{"location":"fwk_jenkins/","title":"Framework Jenkins CI","text":"<p>When opening a new Pull Request, an automated tool, Jenkins, takes care of launching a full build. It allows to see directly if your code can be merged without breaking everything. We have a dedicated Jenkins instance running at CERN. Only members of the <code>cp3-llbb</code> CERN e-group can access this page.</p> <p>As soon as a new Pull Request is opened, or if an already opened Pull Request is updated, an automatic build is launched. Only one build can be executed at the same time: every other builds are queued. A build typically takes about 1 hour.</p> <p>Once a build is started, the Pull Request status on GitHub is updated. Once done, the status will either be green (the code compiles) or red (something is wrong). You can click on the <code>Details</code> link to access the Jenkins job report and the compilation log. For more information, see https://github.com/blog/1935-see-results-from-all-pull-request-status-checks.</p> <p>The Pull Request won't be mergeable until the Pull Request status is green.</p> <p>Bootstrap</p> <p>Since the build is automatized, Jenkins needs to know how-to setup the CMSSW env by itself. To do that, two files are necessary:</p> <ul> <li><code>CMSSW.release</code>: This file must contains only a string representing the CMSSW version to use to setup the framework. Be careful not to add a line break at the end of the line.</li> <li><code>CMSSW.arch</code>: The <code>SCRAM_ARCH</code> of the CMSSW release.</li> <li><code>bootstrap_jenkins.sh</code>: This file is a bash script executed by Jenkins just before building the framework, but after the CMSSW env is setup. You must use this file to install all the dependencies of the framework.</li> <li><code>jenkins_postbuild.sh</code>: This file is executed by Jenkins after the compilation.</li> </ul> <p>Do not forget to update these files when changes are done to the release or the dependencies, otherwise the build will fail.</p>"},{"location":"fwk_jenkins/#technical-details","title":"Technical details","text":"<ul> <li>Jenkins instance</li> <li>OpenShift instance: jenkins-cp3-llbb (access is restricted to administrators. If you want / need access, please ask Christophe D. or S\u00e9bastien B.). This is the platform hosting our Jenkins instance inside an isolated container (for more information, look for Docker on Google).</li> </ul> <p>A github bot also exists; it's a generic github user, member of the cp3-llbb organization. It needs push authorization to a repository to properly update the PR status. Password for this user can be found on the protected CP3 wiki</p> <p>Note</p> <p>Sometimes, the container responsible for the build get stuck in creating phase and you'll need to kill it and retrigger a new build. To do that, connect to the OpenShift instance, and select on the left menu <code>Applications</code> \u2192 <code>Pods</code>. Click on the build instance in the list, and on the new page, select <code>Delete</code> in the <code>Actions</code> menu (top right). It may takes some time before the container is killed. If it's still stuck in deleting after a few minutes, you'll have to open a new ticket here.</p>"},{"location":"fwk_jenkins/#troubleshooting","title":"Troubleshooting","text":"<p>If a build/test fails because of unexpected connection glitch, you can re-trigger jenkins by commenting <code>please test</code> to the pull request</p>"},{"location":"gridin/","title":"GridIn: tools for running over grid","text":"<p>Note</p> <ul> <li>This guide suppose that the framework is already installed. See the framework guide for detailed instructions</li> <li>This guide installs the GridIn tools, our Datasets repo to list the datasets to be ran on, and SAMADhi, our local database</li> <li>You probably want to have the access to this database: ask around!</li> <li>The utilities in the <code>scripts</code> folders are copied to <code>CMSSW/bin</code> during the <code>scram b</code>, so if these utilities have been modified you need to rebuild in order to have them in your PATH</li> </ul>"},{"location":"gridin/#first-time-setup","title":"First time setup","text":"<pre><code>source /nfs/soft/grid/ui_sl6/setup/grid-env.sh\nsource /cvmfs/cms.cern.ch/cmsset_default.sh\nsource /cvmfs/cms.cern.ch/crab3/crab.sh\n\ncd &lt;path_to_CMSSW&gt;\ncmsenv\n\ncd ${CMSSW_BASE}/src\ngit clone -o upstream git@github.com:cp3-llbb/GridIn.git cp3_llbb/GridIn\ngit clone -o upstream git@github.com:cp3-llbb/SAMADhi.git cp3_llbb/SAMADhi\ngit clone -o upstream git@github.com:cp3-llbb/Datasets.git cp3_llbb/Datasets\n\nscram b -j 4\ncd ${CMSSW_BASE}/src/cp3_llbb/GridIn\nsource first_setup.sh\n</code></pre>"},{"location":"gridin/#how-to","title":"How-to","text":"<p>The script you'll be working with is <code>runOnGrid.py</code>, from the <code>scripts</code> folder. During the first build, this script is copied by CMSSW into the global <code>scripts</code> directory, which is inside <code>PATH</code>; you can thus access it from anywhere in the source tree</p> <p>In order to run on the grid, you need 3 things:</p> <ul> <li>First, an <code>analyzer</code> for the framework</li> <li>A <code>configuration</code> file for this analyzer</li> <li>A set of JSON files describing the datasets you want to run on</li> </ul> <p>The first two points must be handled by you. For the last point, a set of JSON files for the commonly used datasets are already included (see inside <code>test/datasets</code>). The structure of the JSON file is described below</p> <p>You can now run on the grid. Go to the <code>test</code> folder, and run</p> <pre><code>runOnGrid.py -c &lt;Your_Configuration_File&gt; --mc datasets/mc_TT.json datasets/mc_DY.json &lt;datasets/...&gt;\n</code></pre> <p><code>&lt;Your_Configuration_File&gt;</code> must be substituted by the name of the configuration file, including the <code>.py</code> extension. You should now have a new file inside the working directory, named <code>crab_TTJets_TuneCUETP8M1_amcatnloFXFX_25ns.py</code>. This file is a configuration file for <code>crab3</code>. A file is created automatically for each dataset specified when running  <code>runOnGrid.py</code>.</p> <p>Note</p> <p>By default, <code>runOnGrid.py</code> does not submit any jobs to the grid, it only creates the necessary files for crab. If you want to automatically submit the jobs, you can add the <code>--submit</code> flag when running <code>runOnGrid.py</code> (does not seems to work for the moment due to a crab bug).</p> <p>To manually launch the jobs, use the <code>crab submit &lt;crab_python_file&gt;</code>. All the submitted tasks are stored inside the <code>tasks</code> folder.</p>"},{"location":"gridin/#book-keeping","title":"Book-keeping","text":"<p>If the job has completed successfully, you can run <pre><code>runPostCrab.py &lt;myCrabConfigFile.py&gt;\n</code></pre> This will gather the needed information (number of events, code version, source dataset, ...) and insert the sample (and possibly the parent dataset if missing) in the database</p>"},{"location":"gridin/#json-file-format","title":"JSON file format","text":"<p>Each dataset is stored inside a JSON file, containing at least the dataset pretty name, its path as well as the number of units per job. The meaning of units depends on the type of dataset: for <code>data</code>, a unit is a luminosity section. For <code>MC</code>, a unit is a file.</p> <p>An example of JSON file is given below: <pre><code>{\n  \"/TTJets_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8/RunIISpring15DR74-Asympt25ns_MCRUN2_74_V9-v1/MINIAODSIM\": {\n    \"name\": \"TTJets_TuneCUETP8M1_amcatnloFXFX_25ns\",\n    \"units_per_job\": 15\n  }\n}\n</code></pre></p> <p>It can contains any number of datasets, but by convention, only datasets belonging into the same group should be into the same file (for example, it's fine to have one file for exclusive DY datasets, but not one file for all the different TT samples). The root node must be a dictionary, where the key is the dataset path, and values are:</p> <ul> <li><code>name</code>: The pretty name of the dataset. This name is used to format the task name and the output path</li> <li><code>units_per_job</code>: For <code>MC</code>, the number of files processed by each job. For <code>data</code>, the number of luminosity section processed by each job.</li> </ul> <p>For a <code>data</code> JSON file, an additional value is mandatory:</p> <ul> <li><code>run_range</code>: must be an array with two entries, like <code>[1, 30]</code>, defining the range of validity of the dataset</li> </ul> <p>An optional value, but highly recommended is:</p> <ul> <li><code>certified_lumi_file</code>: the path (filename or url) of the golden JSON file containing certified luminosity section. If not present, a default file will be used, presumably outdated by the time you'll run.</li> </ul>"},{"location":"plotit/","title":"plotIt","text":"<p>plotIt is a utility to plot ROOT histogram stacks. The input files corresponding to the different contributions and the histograms to fit are configured through a yaml file.</p>"},{"location":"plotit/#first-time-setup-instructions","title":"First time setup instructions","text":"<pre><code>git clone -o upstream https://github.com/cp3-llbb/plotIt.git # inside $CMSSW_BASE/src/cp3_llbb\ncd plotIt/\n\n# Initialize the git remotes\nsource firstsetup.sh \n# Within-CMSSW and on ingrid specific install\ncms_env # specific to ingrid, aka 'module purge; module load grid/grid_environment_sl6; module load crab/crab3; module load cms/cmssw;'\ncmsenv\nsource setup_for_cms_env.sh\n# For a non-CMSSW and non-ingrid install (beware there is no cmsenv at all in this case):\n# source setup_sl6_env.sh\n\n# Build externals\ncd external\n./build-external.sh\n# Build the executable itself\ncd ..\nmake -j 4\n</code></pre> <p>Outside CMSSW and with a recent version of ROOT, plotIt can als be built with CMake (and an install prefix passed with <code>-DCMAKE_INSTALL_PREFIX</code>, or the exectuble copied from the build directory to install), e.g. <pre><code>git clone -o upstream https://github.com/cp3-llbb/plotIt.git\nmkdir plotit-build\ncd plotit-build\ncmake ../plotIt\nmake -j2\ncd -\n</code></pre></p>"},{"location":"plotit/#test-run-command-line","title":"Test run (command line)","text":"<pre><code># Load the proper environment (if not already done)\nsource setup_sl6_env.sh\n# Create some dumb root files to play with\ncd test\nroot -l -b -q generate_files.C\n# Now plot stuff\n./../plotIt -o plots/ example.yml\n# Go to the plots directory to observe the beautiful plots\n</code></pre>"},{"location":"plotit/#optional-command-line-arguments","title":"Optional command-line arguments","text":"<p>The command above is the minimal way to run plotIt: with a configuration file and output directory. There are also a number of optional arguments that change the behaviour:</p> <ul> <li><code>-h</code>: print help for the command-line interface and exit</li> <li><code>-v</code>: verbose output, will print more progress messages, a summary, and the LaTeX yields table (if <code>-y</code> is also specified) to stdout</li> <li><code>-b</code>: print systematics details for each MC process in the summary</li> <li><code>-o</code>: output directory</li> <li><code>-i</code>: input directory (file names are taken relative to this directory, default is the current directory)</li> <li><code>-y</code>: produce a yields table (written to <code>&lt;output&gt;/yields.tex</code>)</li> <li><code>-p</code>: do not produce the plots</li> <li><code>--ignore-scales</code>: ignore (global and per-file) <code>scale</code> parameters for the normalisation</li> <li><code>-e</code>: pass one era to make plots for (otherwise combined plots, summing over all eras specified in the configuration, are made)</li> <li><code>-u</code>: unblind, i.e. ignore any blinded-range in the configuration</li> </ul>"},{"location":"plotit/#configuration-file-reference","title":"Configuration file reference","text":"<ul> <li><code>Point</code>s and <code>Range</code>s are lists of two numbers: <code>[x,y]</code></li> <li><code>Position</code>s are lists of four numbers: <code>[x1, y1, x2, y2]</code></li> <li>Some strings are formatted using boost::format. Arguments passed to the formatting are described below.</li> <li>Strings used for labels, axis titles, legends, ... can use TLatex</li> <li>Line styles and widths, fill styles and marker styles are numbers, see the corresponding <code>TAtt...</code> class references or the lists below for some common values</li> <li>Colors are either basic ROOT colors (ie 42) or hexadecimal (alpha)RGB (ie #FFFFCC)</li> </ul>"},{"location":"plotit/#plotit-general-configuration","title":"plotIt general ('configuration')","text":"Field Type Action Default width number Width (in pixels) of the plots <code>800</code> height number Height (in pixels) of the plots <code>800</code> experiment string Name of the experiment, appearing in bold above the plot <code>CMS</code> extra-label string Additional text above the plot root string Path to the folder where the files are located <code>./</code> scale number Global scaling of all non-data entries <code>1</code> eras list of strings List of data-taking periods to combine <code>[\"\"]</code> luminosity number or map Integrated luminosity (in pb) used to normalise MC to data. Used by the luminosity label. When using eras: map of <code>{ era : luminosity }</code> luminosity-error number Fractional uncertainty on the integrated luminosity. Used for the yields table (uncertainty on MC and data/MC ratio) and the plot's MC &amp; ratio syst. error bands. <code>0</code> luminosity-label string Luminosity label appearing above the plot. In the string, <code>%lumi%</code> gets replaced by the integrated luminosity in fb. error-fill-color color <code>42</code> error-fill-style fill style <code>3154</code> fit-line-color color <code>46</code> fit-line-style line style <code>1</code> fit-line-width line width <code>1</code> fit-error-fill-color color <code>42</code> fit-error-fill-style fill style <code>1001</code> fit-n-points number <code>1000</code> ratio-fit-line-color color <code>46</code> ratio-fit-line-style line style <code>1</code> ratio-fit-line-width line width <code>1</code> ratio-fit-error-fill-color color <code>42</code> ratio-fit-error-fill-style fill style <code>1001</code> ratio-fit-n-points number <code>1000</code> blinded-range-fill-color color <code>42</code> blinded-range-fill-style fill style <code>1001</code> y-axis-format formatted string Arg. 1: plot's y-axis title; Arg. 2: plot's first bin's width <code>%1% / %2$.2f</code> ratio-y-axis string Y axis title of the ratio plot <code>Data / MC</code> ratio-style string Draw option for the ratio histogram <code>P0</code> mode string <code>tree</code> (fill TH1s from a tree on-the-fly) or <code>hist</code> (retrieve TH1s from files) <code>hist</code> tree-name string Name of the TTree used to fill the histograms in <code>tree</code> mode labels Label Extra labels' configurations (see below). show-overflow bool Show under- and overflow false errors-type string <code>normal</code> (ie. sqrt(N)), <code>poisson</code> (68% Poisson interval) or <code>poisson2</code> <code>poisson</code> yields-table-stretch number Stretch of LaTeX table produced <code>1.15</code> yields-table-align string Alignment of the LaTeX table. For now only <code>h</code> (processes horizontal, categories vertical) is supported. <code>h</code> yields-table-text-align string <code>l</code>/<code>r</code>/<code>c</code>: alignment of text in the LaTeX table's entries. <code>c</code> yields-table-numerical-precision-yields number Number of decimals used for the MC yields in the LaTeX table. <code>1</code> yields-table-numerical-precision-ratio number Number of decimals used for the data/MC ratio in the LaTeX table. <code>2</code> line-color color Default color of lines <code>1</code> line-type line style Default style (type) of lines <code>1</code> line-width number Default width of lines <code>1</code> book-keeping-file string If set, store all the produced plots into this file in addition to create graphic files none x-axis-label-size number The size of the labels on the x-axis, in pixel <code>18</code> y-axis-label-size number The size of the labels on the y-axis, in pixel <code>18</code> x-axis-top-ticks bool Show ticks at the top of the frame <code>True</code> y-axis-right-ticks bool Show ticks at the right of the frame <code>True</code> transparent-background bool Transparent background for canvas and legend <code>False</code>"},{"location":"plotit/#plots-configuration-plots","title":"Plots configuration ('plots')","text":"Field Type Action Default exclude string Regexp allowing to exlude histograms present in the files whose name matches the plot's name x-axis string x-axis title y-axis string y-axis title <code>Events</code> y-axis-format formatted string Overrides plotIt option. %1% normalized bool Normalize data/each signal/total MC to 1. <code>false</code> normalizedByBinWidth bool The bin contents and errors are divided by the bin width. <code>false</code> no-data bool Do not plot data. <code>false</code> override bool If any plot has this field set to true, only plots which do will be produced. <code>false</code> log-y bool Log-scale on y-axis. Special value: <code>Both</code>. <code>false</code> log-x bool Log-scale on x-axis. Special value: <code>Both</code>. <code>false</code> save-extensions list of strings Write plot to file in each of this formats (supported by <code>TCanvas::Print()</code>) <code>[pdf]</code> show-ratio bool Show ratio plot under main plot. false fit bool Do a fit false fit-function string Function used for the fit. <code>gaus</code> fit-legend formatted string Fit results. Arg. i: fitted parameter i. <code>#scale[1.6]{#splitline{#mu = %2$.3f}{#sigma = %3$.3f}}</code> fit-legend-position Point Position of the fit results <code>[0.22, 0.87]</code> fit-range Range Restrict fit to this range fit-ratio bool Fit the ratio plot false ratio-fit-function string Function used for the ratio fit. <code>pol1</code> ratio-fit-legend formatted string Ratio fit results. Arg. i: fitted parameter i. ratio-fit-legend-position Point Position of the ratio fit results <code>[0.20, 0.38]</code> ratio-fit-range Range Restrict ratio fit to this range show-errors bool Show errors on data points. <code>true</code> x-axis-range Range Range of x-axis. TH1's range log-x-axis-range Range Range of x-axis to be applied only if the x axis is in log scale. Same as x-axis-range y-axis-range Range Range of y-axis. Computed from each TH1's range log-y-axis-range Range Range of y-axis to be applied only if the y axis is in log scale. Same as y-axis-range ratio-y-axis-range Range Range of y-axis for ratio <code>[0.5, 1.5]</code> blinded-range Range Blind a range of data in the plot. Note that the bins that include the values used to specify the range will be blinded, and that the left edge is included in a bin (so you may have to write 4.9999 to blind up to 5, itself excluded). y-axis-show-zero bool Force y-axis range to go down to zero (might not be the case for flat distributions). <code>false</code> inherits-from string <code>TH1</code> rebin number Rebin: merge <code>x</code> bins into one <code>1</code> labels Label Extra labels' configurations (see below). extra-label string legend-position Position Overrides plotIt option. legend-columns number Overrides plotIt option. show-overflow bool Overrides plotIt option. errors-type string Overrides plotIt option. binning-x number binning-y number draw-string string In <code>tree</code> mode, formula used to fill the histogram selection-string string In <code>tree</code> mode, formula used to select events when filling histogram for-yields bool Plot defines an entry as a category in the LaTeX yields table. <code>false</code> yields-title string Name of the category in the table. Must be valid LaTeX text string! plot's name yields-table-order number Order of appearance of the category in the yields table (small=up). <code>0</code> vertical-lines Line Draw vertical lines on the plot Empty horizontal-lines Line Draw horizontal lines on the plot Empty lines Line Draw arbitrary lines on the plot Empty rename List of renaming operations Apply a set of renaming operations to the output filename sort-by-yields bool If <code>true</code>, histograms inside a given stack are sorted by yields, the smallest one at the bottom of the stack. This is the default behavior. Set to <code>false</code> to disable. <code>true</code> x-axis-label-size number The size of the labels on the x-axis, in pixel Value of <code>x-axis-label-size</code> of the main configuration y-axis-label-size number The size of the labels on the y-axis, in pixel Value of <code>y-axis-label-size</code> of the main configuration x-axis-hide-ticks bool Hide ticks on the <code>x</code> axis <code>False</code> y-axis-hide-ticks bool Hide ticks on the <code>y</code> axis <code>False</code> ratio-y-axis string Y axis title of the ratio plot Value of <code>ratio-y-axis</code> of the main configuration"},{"location":"plotit/#files-configuration-files","title":"Files configuration ('files')","text":"<p>Each MC contribution is scaled by <code>plotIt.scale*&lt;luminosity&gt;*scale*cross-section*branching-ratio/generated-events</code>, where <code>&lt;luminosity&gt;</code> is the luminosity for the <code>era</code> of the file, or the total luminosity if no <code>era</code> is specified.</p> Field Type Action Default type string <code>data</code>, <code>mc</code> (all MC are stacked based on their <code>stack-index</code>) or <code>signal</code> (not stacked) <code>mc</code> scale number Scale this contribution <code>1</code> cross-section number Cross-section of the process <code>1</code> branching-ratio number Branching ratio of the process <code>1</code> generated-events number Careful! Sum of generated event weights! Can be different from the number of generated events. <code>1</code> era string era (used to select the corresponding integrated luminosity value for normalisation of MC, when using eras) order number Order in which the histograms are stacked (concerns MC only). Small=low. legend string Name of the file in the legend, unless <code>group</code> is defined . group Group Refers to a legend group (see below) yields-group string Used to group contributions in the LaTeX yields table (does't use a \"group\" node such as the legend groups). In this order, defaults to <code>group</code>, <code>legend</code> or the file's name. systematics Systematics Set of systematics nodes, as defined below. drawing-options string Possibility to override TH1::Draw() option. <code>hist</code> for signals and MC, <code>P</code> for data. fill-color color For this and the following: <code>-1</code> means that the quantity is not set. MC: <code>1</code>, else: <code>-1</code> fill-type fill style MC: <code>1001</code> , signal: <code>0</code>, else: <code>-1</code> line-color color MC: <code>-1</code>, else: <code>1</code> line-type line style signal: <code>2</code>, else: <code>-1</code> line-width line width MC: <code>0</code>, else: <code>1</code> marker-color color MC &amp; signal: <code>-1</code>, else: <code>1</code> marker-type marker style MC &amp; signal: <code>-1</code>, else: <code>20</code> marker-size number MC &amp; signal: <code>-1</code>, else: <code>1</code> stack-index number Only MC files with the same <code>stack-index</code> are stacked together. Useful to have multiple stacks in the same plot <code>0</code> rename List of renaming operations Apply a set of renaming operations to all the histograms loaded from this file. It can be used for example to plot two different histograms from the same input file"},{"location":"plotit/#additional-fields","title":"Additional fields","text":""},{"location":"plotit/#groups-groups","title":"Groups ('groups')","text":""},{"location":"plotit/#legend-legend","title":"Legend ('legend')","text":""},{"location":"plotit/#systematics-configuration-systematics","title":"Systematics configuration ('systematics')","text":"<p>Different types of systematic uncertainties are supported: shape, log-normal and constant.</p> <p>Each shape uncertainty requires an up and down variated histogram. They are retrieved using its name, specified in the yml file as:</p> <p><pre><code>systematics:\n  - &lt;systematic&gt;\n</code></pre> Or, equivalently: <pre><code>systematics:\n  - &lt;systematic&gt;:\n     type: shape\n</code></pre> Based on this, plotIt will either look for two histograms called <code>&lt;nominal&gt;__&lt;systematic&gt;[up|down]</code>, where <code>&lt;nominal&gt;</code> is the nominal histogram, in the file containing all the nominal histograms, or look for histograms called <code>&lt;nominal&gt;</code> in two files called <code>&lt;nominalFile&gt;__&lt;systematic&gt;[up|down].root</code> (where <code>&lt;nominalFile&gt;</code> is the file containing the nominal histograms for that process).</p> <p>A constant systematic is just a rate uncertainty, which can specified either as: <pre><code>systematics:\n  - &lt;systematic&gt;: &lt;value&gt;\n</code></pre> or as: <pre><code>systematics:\n  - &lt;systematic&gt;:\n     type: const\n     value: &lt;value&gt;\n</code></pre> where <code>&lt;value&gt;</code> is the value with which the nominal histogram should be scaled up and down (by <code>&lt;value&gt;</code> and <code>2-&lt;value&gt;</code>): e.g. with <code>1.025</code>, the histograms are scaled by <code>1.025</code> and <code>0.975</code>, i.e. by +/- 2.5%.</p> <p>Any kind of systematics can be restricted to a subset of files by means of a regular expression: <pre><code>systematics:\n  - &lt;systematic&gt;:\n     type: shape\n     on: 'ttbar'\n</code></pre> will only apply the <code>&lt;systematic&gt;</code> on files containing <code>ttbar</code>.</p> <p>When plotting, all uncertainties will be added in quadrature, assuming zero correlations between all of them.</p>"},{"location":"plotit/#additional-labels-labels","title":"Additional labels ('labels')","text":"<p>Each plot can be assigned a set of labels. A label is a custom string which can be positioned anywhere on the canvas. You can defined labels as follow:</p> <p><pre><code>labels:\n  - {&lt;label1&gt;}\n  - {&lt;label2&gt;}\n</code></pre> Each label has the following fields:</p> Field Type Action Default text string Text of the label. Support <code>TLatex</code> syntax (<code>#splitline{}{}</code> is especially useful for multi-line labels) position Point Position of the label on the canvas size number Font size of the label (in pixel) <code>18</code> <p>Example</p> <pre><code>plots:\n  'Plot':\n    x-axis: \"X axis\"\n    y-axis: \"Y axis\"\n    labels:\n      - {text: 'Label', position: [0.7, 0.7]}\n      - {text: 'Label 2', position: [0.3, 0.7]}\n</code></pre>"},{"location":"plotit/#lines","title":"Lines","text":"<p>You can draw lines over a plot using the <code>vertical-lines</code>, <code>horizontal-lines</code> and <code>lines</code> plot options. Each option accepts an <code>array</code> of <code>line</code>. A <code>line</code> is defined:</p> <ul> <li>By a number for <code>vertical-lines</code> and <code>horizontal-lines</code>. In this case, the number represents the <code>x</code> or <code>y</code> coordinate of the line (in plot axis units), and the line will span across all the plot.</li> <li>By an <code>array</code> of 2 <code>Point</code>s for <code>lines</code>, where the <code>Point</code>s represent respectively the start point and the end point of the line.</li> </ul> <p>Note</p> <p>in <code>lines</code> definition, you can use the special value <code>.nan</code> for a point coordinate. This value will automatically be replaced by the maximum or minimum of the x or y axis, depending on which place it's used.</p> <p>In addition, styling can be applied to lines either globally in the <code>configuration</code> part, or individually for each line.</p> <ul> <li>In global configuration, you can set the <code>line-color</code>, <code>line-width</code> and <code>line-type</code> options. This will affect all lines.</li> <li>If you want to change the style individually, then you must convert the <code>line</code> definition into a <code>map</code>. The <code>value</code> key will hold the previous line definition (ie, either a number or an <code>array</code> of 2 <code>Point</code>s), and you can set the <code>line-color</code>, <code>line-width</code> and <code>line-type</code> as you would do in the global configuration.</li> </ul> <p>If you want a specific line to be drawn on the ratio instead of the main plot, you can set the <code>pad</code> option to <code>bottom</code> (it defaults to <code>top</code>).</p> <p>Example</p> <pre><code>plots:\n  'histo1':\n    # Draw two vertical lines at x = 3 and x = 7. The first line is stylized individually and drawn on the ratio\n    vertical-lines:\n      - {\n          line-color: 10,\n          line-type: 4,\n          pad: bottom,\n          value: 3\n        },\n      - 7\n    # Draw one horizontal line at y = 80\n    horizontal-lines:\n      - 80\n    # Draw:\n    # 1 line from (3, 20) -&gt; (8, 90)\n    # 1 vertical line at x = 5 (.nan is replaced automatically by the minimum and maximum of the y-axis)\n    lines:\n      - [[3, 20], [8, 90]]\n      - [[5, .nan], [5, .nan]]\n</code></pre>"},{"location":"plotit/#renaming-operations","title":"Renaming operations","text":"<p>A renaming operation is defined in YAML as a dictionary with the keys <code>from</code> and <code>to</code>. <code>from</code> is a regular expression following the extended POSIX syntax. Any string matching this regular expression will be replaced by <code>to</code>. Matching groups are supported and can be accessed using the <code>\\N</code> syntax, where <code>N</code> is the index of the matching group.</p> <p>The <code>rename</code> option expect a list of operation. Renaming operations are applied in sequence, starting from the first occurrence.</p> <p>Example</p> <pre><code>files:\n    'file.root':\n        rename:\n            - from: '([[:alpha:]+)_cut$'\n              to: '\\1_nocut'\n</code></pre>"},{"location":"plotit/#parameters-cheatsheets","title":"Parameters cheatsheets","text":""},{"location":"plotit/#line-styles","title":"Line styles","text":""},{"location":"plotit/#line-widths","title":"Line widths","text":""},{"location":"plotit/#fill-styles","title":"Fill styles","text":""},{"location":"plotit/#marker-styles","title":"Marker styles","text":""},{"location":"plotit/#colors","title":"Colors","text":"<p>ROOT basic colors</p> <p></p> <p></p> <p></p>"}]}